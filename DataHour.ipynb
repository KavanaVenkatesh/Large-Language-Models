{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z_OMG3tm7cF"
   },
   "source": [
    "# Harnessing the Power of LLMs: A Deep Dive into Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Tg8ljSBJnD5P"
   },
   "outputs": [],
   "source": [
    "## Install packages\n",
    "# pip install langchain openai pypdf tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "glWR18t1TAA4"
   },
   "outputs": [],
   "source": [
    "# import packages and load document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W_GZeDH3TOc9"
   },
   "outputs": [],
   "source": [
    "# Set up openai api key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'openai_api_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIfgX3_O1NSm"
   },
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HW5IIJmunV0l"
   },
   "source": [
    "### 1) Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZG03APUnmTD"
   },
   "source": [
    "Zero-shot prompting entails relying solely on an LLM's pre-trained information to answer a given user prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ij32J1ECyenF"
   },
   "source": [
    "#### Simple Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "4Fbs7rwOyQkH",
    "outputId": "875b2821-508d-4b63-8500-fb63d07ff9b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"In 1917, Mahatma Gandhi returned to India from South Africa and began his civil disobedience campaign against British colonial rule. He called for peaceful protests and non-cooperation with the British, inspiring millions of Indians to join the struggle for independence. This was the beginning of the Indian independence movement, which eventually led to India's independence in 1947.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"You are an expert historian. Given the {year} and {country}, give a brief description of any important historical\n",
    "                     event that happened in the country in that year.\n",
    "                     Answer it to the best of your knowledge.\n",
    "                     If you do not know the answer, say so and do not make up factually incorrect answers.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template = prompt_template, input_variables=['year', 'country'])\n",
    "\n",
    "chain = LLMChain(llm = OpenAI(), prompt = prompt)\n",
    "chain.run(year = '1917', country = 'India').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1PbmBjr1D28"
   },
   "source": [
    "#### Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZHnQcuI1fmw"
   },
   "source": [
    "Prompt chaining is a method of using LLMs to accomplish a task by breaking it into multiple smaller prompts and passing the output of one prompt as the input to the next. It simplifies complex tasks and streamlines the interaction with the AI model.\n",
    "\n",
    "You can chain multiple prompts using the SequentialChain provided by LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "g9lHKUwEm5rI"
   },
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play and the era it is set in.\n",
    "llm = OpenAI(temperature=.7)\n",
    "synopsis_template = \"\"\"You are a playwright. Given the title of play and the era it is set in,\n",
    "                       it is your job to write a synopsis for that title.\n",
    "\n",
    "Title: {title}\n",
    "Era: {era}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "synopsis_prompt_template = PromptTemplate(input_variables=[\"title\", \"era\"], template=synopsis_template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=synopsis_prompt_template, output_key=\"synopsis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LABCQ2MBm5ty"
   },
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "c-vNDiEh2tDi"
   },
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"synopsis\", \"review\"],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aRdAF6X2tFk",
    "outputId": "6b00b54a-9102-48e7-d746-88616dfa2a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Tragedy at sunset on the beach',\n",
       " 'era': 'Victorian England',\n",
       " 'synopsis': \"\\n\\nTragedy at Sunset on the Beach is a story set in Victorian England about a young woman named Alice who finds herself in a difficult situation. She is from a wealthy family and has been betrothed to a man she does not love. When she attempts to escape her fate, she finds herself in a small fishing village on the shore of the English coast.\\n\\nAlice's arrival in the village sparks a chain of events that lead to a tragic ending. As the townspeople come to know Alice and her story, her presence brings out their own secrets and conflicts, resulting in a clash of emotions and ideologies.\\n\\nThe play follows Alice as she struggles to reconcile her own desires with the expectations of the townspeople. By the end of the play, Alice is forced to come to terms with her own mortality and the realities of life in Victorian England. As the sun sets on the beach, Alice must make a heartbreaking decision that will have lasting consequences for her and the village.\",\n",
       " 'review': '\\n\\nTragedy at Sunset on the Beach is a beautiful and thoughtful exploration of the human condition set against a backdrop of Victorian England. Through its compelling story of Alice, a young woman from a wealthy family who finds herself in a difficult situation, the play examines the tension between external expectations and personal desires.\\n\\nThe play is wonderfully acted and directed, with each character realistically drawn and engaging. From the townspeople to Alice herself, there is a complex and ever-shifting balance of emotions at work. As Alice struggles to reconcile her own desires with the expectations of the townspeople, the audience is taken on a journey of emotions that culminates in a heartbreaking climax.\\n\\nTragedy at Sunset on the Beach is a must-see play that captures the complexities of the human heart in a beautiful and powerful way. It is an excellent example of how theatre can be used to explore the timeless themes of love, loss, and mortality. Highly recommended.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain({\"title\":\"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8YRIOlM3SlS"
   },
   "source": [
    "### Prompt Pipelining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma97C-JX5PMp"
   },
   "source": [
    "The idea behind prompt pipelining is to provide a user friendly interface for composing different parts of prompts together. You can do this with either string prompts or chat prompts. Constructing prompts this way allows for easy reuse of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "F8DPpAYI2tLk",
    "outputId": "8d0bab64-ed11-4544-c178-4a7d5a6cdb84"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"1. A blue whale's heart is the size of a car!\\n2. The aorta of a blue whale is large enough for a human to swim through!\\n3. Blue whales have the loudest call of any animal on Earth, reaching up to 188 decibels!\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = (\n",
    "    PromptTemplate.from_template(\"Return {number_of_facts} witty fun facts\")\n",
    "    + \", Keep them intriguing and short\"\n",
    "    + \"\\n\\nabout {topic}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm = OpenAI(), prompt = prompt)\n",
    "chain.run(number_of_facts = 3, topic = 'Blue Whales').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLnpt1It5XDl"
   },
   "source": [
    "### 2) Few Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPI0nlTJ6FuD"
   },
   "source": [
    "Few-shot prompting is a technique that uses a few examples to guide AI to respond in a specific way.\n",
    "\n",
    "It can be used when: \\\n",
    "\n",
    "* The output needs to be structured in a specific way that is difficult to describe to the model\n",
    "* You want to enhance code generation tasks\n",
    "* You want to create natural language text with a limited amount of input data\n",
    "* You want to apply it to various NLP tasks like text classification, sentiment analysis, and language translation\n",
    "\n",
    "Few-shot prompting fine-tunes the model with minimal examples for enhanced accuracy. It can be used in the context of prompt engineering.\n",
    "Here are some examples of when to use few-shot prompting:\n",
    "\n",
    "* Code generation\n",
    "* Creating natural language text with a limited amount of input data\n",
    "* Text classification\n",
    "* Sentiment analysis\n",
    "* Language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_QBSYGc938w_"
   },
   "outputs": [],
   "source": [
    "# Given a paragraph of text, extract names, places and dates from the text\n",
    "\n",
    "# Few shot training examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input_text\": \"\"\"On a brisk autumn day in Paris, Élise met Antoine for the first time at the charming Café L'Amour on October 12, 2022.\n",
    "                Their eyes locked beneath the Eiffel Tower's elegant glow, and from that moment, their love story began. They decided\n",
    "                to explore the City of Light together, strolling along the Seine, visiting the Louvre, and savoring macarons at Ladurée.\n",
    "                As the days turned into weeks, their connection deepened, and they couldn't wait to create more memories in this\n",
    "                enchanting city. Below the example_id is the sum of the count of elements in each list followed by '_train1012'.\"\"\",\n",
    "        \"output_data\": \"Names - Élise, Antoine, Places - Eiffel Tower, Café L'Amour, Seine, The Louvre, Ladurée, Date - October 12, 2022\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"input_text\": \"\"\"In the bustling streets of New York City, Sarah and Michael had their first encounter on a rainy evening in Times Square\n",
    "                on May 5, 2019. They immediately felt a connection as they sought shelter from the downpour, and their love story began.\n",
    "                Over the years, they explored Central Park, dined in the charming cafes of Greenwich Village, and made memories in the\n",
    "                city that never sleeps.\"\"\",\n",
    "        \"output_data\": \"Names - Sarah, Michael, Places - New York City, Times Square, Central Park, Greenwich Village, Date - May 5, 2019\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"input_text\": \"\"\"Amidst the serene landscapes of Kyoto, Japan, Sakura and Hiroshi found love in the tranquil Arashiyama Bamboo Grove\n",
    "                on a sunny spring day, April 18, 2021. Their hearts intertwined as they walked among the towering bamboo, creating\n",
    "                an unbreakable bond. They continued their journey through the historic Gion District, savoring traditional Japanese\n",
    "                cuisine and embracing the beauty of Kyoto's temples.\"\"\",\n",
    "        \"output_data\": \"Names - Sakura, Hiroshi, Places - Kyoto, Japan, Arashiyama Bamboo Grove, Gion District, Date - April 18, 2021\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "c0wc9O1E38zQ",
    "outputId": "241114f8-4977-4d79-f190-936e61aca288"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Instruction: Given text: On a brisk autumn day in Paris, Élise met Antoine for the first time at the charming Café L'Amour on October 12, 2022. \\n                Their eyes locked beneath the Eiffel Tower's elegant glow, and from that moment, their love story began. They decided \\n                to explore the City of Light together, strolling along the Seine, visiting the Louvre, and savoring macarons at Ladurée. \\n                As the days turned into weeks, their connection deepened, and they couldn't wait to create more memories in this \\n                enchanting city. Below the example_id is the sum of the count of elements in each list followed by '_train1012'.\\nAI Answer: Names - Élise, Antoine, Places - Eiffel Tower, Café L'Amour, Seine, The Louvre, Ladurée, Date - October 12, 2022\\n\\nInstruction: Given text: In the bustling streets of New York City, Sarah and Michael had their first encounter on a rainy evening in Times Square \\n                on May 5, 2019. They immediately felt a connection as they sought shelter from the downpour, and their love story began. \\n                Over the years, they explored Central Park, dined in the charming cafes of Greenwich Village, and made memories in the \\n                city that never sleeps.\\nAI Answer: Names - Sarah, Michael, Places - New York City, Times Square, Central Park, Greenwich Village, Date - May 5, 2019\\n\\nInstruction: Given text: Amidst the serene landscapes of Kyoto, Japan, Sakura and Hiroshi found love in the tranquil Arashiyama Bamboo Grove \\n                on a sunny spring day, April 18, 2021. Their hearts intertwined as they walked among the towering bamboo, creating \\n                an unbreakable bond. They continued their journey through the historic Gion District, savoring traditional Japanese \\n                cuisine and embracing the beauty of Kyoto's temples.\\nAI Answer: Names - Sakura, Hiroshi, Places - Kyoto, Japan, Arashiyama Bamboo Grove, Gion District, Date - April 18, 2021\\n\\nGiven text: In the colorful streets of Jaipur, India, Priya and Raj shared a timeless love story as they explored the historic Pink City. \\n          Their journey began on a sunny day in October 10, 2020, at the magnificent Amer Fort, where their eyes met amidst the \\n          intricate architecture and vibrant elephant processions. They continued to uncover the city's treasures, from the Hawa Mahal's \\n          intricate windows to the bustling markets of Johari Bazaar, all while savoring the flavors of Rajasthani cuisine.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_template = PromptTemplate(template = \"Instruction: Given text: {input_text}\\nAI Answer: {output_data}\",\n",
    "                                  input_variables=['input_text', 'output_data'])\n",
    "\n",
    "fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=fewshot_template,\n",
    "    suffix=\"Given text: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "# Take a look at the prompt being input to the LLM for inference using few shot training\n",
    "text = \"\"\"In the colorful streets of Jaipur, India, Priya and Raj shared a timeless love story as they explored the historic Pink City.\n",
    "          Their journey began on a sunny day in October 10, 2020, at the magnificent Amer Fort, where their eyes met amidst the\n",
    "          intricate architecture and vibrant elephant processions. They continued to uncover the city's treasures, from the Hawa Mahal's\n",
    "          intricate windows to the bustling markets of Johari Bazaar, all while savoring the flavors of Rajasthani cuisine.\"\"\"\n",
    "\n",
    "fewshot_prompt.format(input = text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gZ2IfbLN382p",
    "outputId": "368a5022-8ae5-480b-9d38-2e05257614de"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'AI Answer: Names - Priya, Raj, Places - Jaipur, India, Amer Fort, Hawa Mahal, Johari Bazaar, Date - October 10, 2020'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference on new paragraph\n",
    "chain = LLMChain(llm = OpenAI(), prompt = fewshot_prompt)\n",
    "chain.run(text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxZ2nHaU_RHc"
   },
   "source": [
    "## Question-Answering on Custom Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUaeKG46_k7i"
   },
   "source": [
    "Although LLMs are powerful, they do not know about information they were not trained on. If you want to use an LLM to answer questions about documents it was not trained on, you have to give it information about those documents. The most common way to do this is through \"retrieval augmented generation\".\n",
    "\n",
    "The idea of retrieval augmented generation is that when given a\n",
    "question you first do a retrieval step to fetch any relevant documents. You then pass those documents, along with the original question, to the language model and have it generate a response. In order to do this, however, you first have to have your documents in a format where they can be queried in such a manner. This page goes over the high level ideas between those two steps:\n",
    "\n",
    "(1) ingestion of documents into a queriable format \\\n",
    "(2) the retrieval augmented generation chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "PtxmRFKSm5y0",
    "outputId": "cc3d5274-c2fc-4991-8d3a-147881914a10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" This policy paper provides an overview of Growth Mindset Thinking and Beliefs in Teaching and Learning. It outlines key characteristics of school policies that facilitate a growth mindset, examines programs and practices to support a growth mindset, and suggests strategies to foster an environment in which students understand and adopt growth mindset thinking. It was created through a mixed methods literature review of research from academic databases and popular, practitioner-oriented sources, and recommends ways to improve students' growth mindset thinking and beliefs.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the custom PDF document\n",
    "pdf_loader = PyPDFLoader(\"growth-mindset-policy-paper.pdf\")\n",
    "pdf_doc = pdf_loader.load()\n",
    "\n",
    "# map_reduce qa_chain\n",
    "chain = load_qa_chain(llm = OpenAI(), chain_type = 'map_reduce')\n",
    "query = 'Summarize the content of the paper?'\n",
    "chain.run(input_documents = pdf_doc, question = query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf4CYNRcAP3k"
   },
   "source": [
    "There are different types of chain available:\n",
    "\n",
    "1) stuff: uses ALL of the text from the documents in the prompt. It actually doesn’t work with our example because it exceeds the token limit and causes rate-limiting errors. That’s why in this example, we had to use other chain types for example \"map_reduce\". \n",
    "\n",
    "2) map_reduce: It separates texts into batches (as an example, you can define batch size in llm=OpenAI(batch_size=5)), feeds each batch with the question to LLM separately, and comes up with the final answer based on the answers from each batch.\n",
    "\n",
    "3) refine : It separates texts into batches, feeds the first batch to LLM, and feeds the answer and the second batch to LLM. It refines the answer by going through all the batches.\n",
    "\n",
    "4) map-rerank: It separates texts into batches, feeds each batch to LLM, returns a score of how fully it answers the question, and comes up with the final answer based on the high-scored answers from each batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfKcX5SoBSqC"
   },
   "source": [
    "## Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uG_a-A8MBb-f"
   },
   "source": [
    "### RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "Wpl3-MVom54i",
    "outputId": "f8527cbe-ebe1-48bc-8bad-11631244d468"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' Parents can foster growth mindset thinking in their children by modeling growth mindset thinking, using growth mindset language, openly discussing learning with their child, and encouraging risk-taking and learning from mistakes. They should also use growth mindset language when providing praise to children by praising effort, hard work, persistence, rising to a challenge, learning from a mistake, and creative use of strategies.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(pdf_doc)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"map_reduce\", retriever=docsearch.as_retriever())\n",
    "\n",
    "query = \"What role do parents play in enabling the growth mindset in students?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hdhky-RaBxMm"
   },
   "source": [
    "### ConversationalRetrieval Chain and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "CtTsK12IBY5k",
    "outputId": "7d14e0ac-eed6-4045-d427-4b8dfdcabfdd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' Parents should model growth mindset behavior and language, use growth mindset language when providing praise to their children, openly discuss learning with their children, and encourage risk-taking and learning from mistakes.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the object to hold memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), docsearch.as_retriever(), memory=memory)\n",
    "\n",
    "query = \"What is the role of parents to enable growth mindset in students?\"\n",
    "result = qa({\"question\": query})\n",
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "CO6cibuDBY7i",
    "outputId": "056c4c47-c309-45ba-aeeb-324d03917d6a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" A parent's fixed mindset can influence their child's learning by sending a message that abilities are not malleable. This can lead the child to believe that their abilities are fixed and not something that can be developed through effort and practice. Additionally, when parents focus on praising the child for being smart, this can promote a fixed mindset in the child.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followup_query = \"How do parents with fixed mindset affect students?\"\n",
    "result = qa({\"question\": followup_query})\n",
    "result['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVrz8EiiCojm"
   },
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32KSZJteDdkJ"
   },
   "source": [
    "This is an agent specifically optimized for doing retrieval when necessary and also holding a conversation.\n",
    "\n",
    "To start, we will set up the retriever we want to use, and then turn it into a retriever tool. Next, we will use the high level constructor for this type of agent. Finally, we will walk through how to construct a conversational retrieval agent from components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "vtkRl8VhTOfa"
   },
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "\n",
    "retriever = docsearch.as_retriever()\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_state_of_union\",\n",
    "    \"Searches and returns documents regarding the state-of-the-union.\"\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MzgU9XGEGKO"
   },
   "source": [
    "Here, we will use the high level create_conversational_retrieval_agent API to construct the agent.\n",
    "\n",
    "Notice that beside the list of tools, the only thing we need to pass in is a language model to use. Under the hood, this agent is using the OpenAIFunctionsAgent, so we need to use an ChatOpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "jrOjZsk4EDtA"
   },
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature = 0)\n",
    "\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVsnQVqHEDvg",
    "outputId": "ea9bcad9-7c96-41ba-9a47-cc087c231785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"Hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lO7WG1RlEDyO",
    "outputId": "5895cd09-285d-457a-ca70-d565504ef6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mParents play a crucial role in enabling a growth mindset in students. Here are some ways parents can support and foster a growth mindset in their children:\n",
      "\n",
      "1. Encourage effort and perseverance: Parents should emphasize the importance of effort and hard work rather than focusing solely on outcomes or grades. Praising children for their effort, resilience, and perseverance can help them develop a belief that their abilities can be developed through dedication and practice.\n",
      "\n",
      "2. Provide constructive feedback: Parents should provide specific and constructive feedback to their children, focusing on the process rather than the end result. This helps children understand that mistakes and setbacks are opportunities for learning and growth.\n",
      "\n",
      "3. Set realistic expectations: Parents should set realistic expectations for their children and avoid placing undue pressure on them to achieve specific outcomes. Instead, they should emphasize personal growth, progress, and the development of skills.\n",
      "\n",
      "4. Model a growth mindset: Parents should model a growth mindset themselves by demonstrating a positive attitude towards challenges, setbacks, and learning. Children often learn by observing their parents, so it is important for parents to display a growth mindset in their own actions and words.\n",
      "\n",
      "5. Encourage curiosity and a love for learning: Parents can foster a growth mindset by encouraging their children to explore new interests, ask questions, and pursue their passions. By nurturing a love for learning, parents can help children develop a mindset that values continuous improvement and the acquisition of knowledge.\n",
      "\n",
      "6. Teach problem-solving skills: Parents can teach their children problem-solving skills and help them develop strategies to overcome obstacles. This can include teaching them how to break down complex tasks into smaller, manageable steps and encouraging them to seek alternative solutions when faced with challenges.\n",
      "\n",
      "7. Celebrate progress and effort: Parents should celebrate their children's progress and effort, regardless of the outcome. Recognizing and acknowledging their hard work and improvement can reinforce the belief that growth and development are more important than immediate success.\n",
      "\n",
      "By adopting these strategies, parents can create an environment that supports and nurtures a growth mindset in their children, helping them develop resilience, motivation, and a love for learning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"What is the role of parents to enable growth mindset in students?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_fm-HFCED0Y",
    "outputId": "ded0b051-5bf4-45e0-8cb7-c633ea4e986e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCollaboration between parents and teachers is essential for the success and well-being of students. Here are some ways parents can work with teachers to support their children's education:\n",
      "\n",
      "1. Open and regular communication: Parents should establish open lines of communication with their child's teachers. This can include attending parent-teacher conferences, responding to emails or messages from teachers, and actively participating in school events. Regular communication allows parents and teachers to share information, discuss concerns, and work together to address any challenges or issues.\n",
      "\n",
      "2. Share information about the child: Parents should provide teachers with relevant information about their child, such as their strengths, weaknesses, learning style, and any specific needs or concerns. This information can help teachers better understand and support the child's individual learning needs.\n",
      "\n",
      "3. Support homework and study routines: Parents can reinforce the importance of homework and study routines by creating a conducive environment at home. They can establish a consistent schedule, provide a quiet and organized workspace, and offer guidance and support when needed. Communicating with teachers about homework expectations and seeking clarification, if necessary, can also be helpful.\n",
      "\n",
      "4. Attend school events and meetings: Parents should make an effort to attend school events, such as parent-teacher meetings, curriculum nights, or school performances. These events provide opportunities to meet teachers, learn about the curriculum, and engage in discussions about the child's progress and development.\n",
      "\n",
      "5. Volunteer and participate in school activities: Parents can contribute to the school community by volunteering their time and skills. This can involve assisting in the classroom, organizing events, or joining parent-teacher associations. By actively participating in school activities, parents demonstrate their commitment to their child's education and build positive relationships with teachers and staff.\n",
      "\n",
      "6. Support classroom learning at home: Parents can reinforce classroom learning by engaging in educational activities at home. This can include reading with their child, discussing school topics, helping with projects, or finding educational resources online. By extending learning beyond the classroom, parents can enhance their child's understanding and enthusiasm for learning.\n",
      "\n",
      "7. Address concerns promptly: If parents have concerns about their child's academic progress, behavior, or well-being, they should communicate with the teacher as soon as possible. By addressing concerns promptly, parents and teachers can work together to identify and implement appropriate strategies or interventions to support the child.\n",
      "\n",
      "Remember, every child is unique, and the partnership between parents and teachers should be based on mutual respect, trust, and a shared commitment to the child's success. By working together, parents and teachers can create a supportive and enriching educational experience for students.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"How can parents work with teachers to help students?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6comO367E5PS"
   },
   "source": [
    "## AutoGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "9To_xo2tTOiH"
   },
   "outputs": [],
   "source": [
    "# pip install pyautogen~=0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHQoN1TdTOkp",
    "outputId": "a781e949-ddd9-46ea-c5b4-9ffa19df6e8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The specified config_list file 'OAI_CONFIG_LIST' does not exist.\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "\n",
    "config_list_gpt35 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-3.5-turbo\",\n",
    "            \"gpt-3.5-turbo-16k\",\n",
    "            \"gpt-3.5-turbo-0301\",\n",
    "            \"chatgpt-35-turbo-0301\",\n",
    "            \"gpt-35-turbo-v0301\",\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HhKpYSDyTOm6"
   },
   "outputs": [],
   "source": [
    "config_list = [\n",
    "{\n",
    "'model': 'gpt-3.5-turbo',\n",
    "'api_key': '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',\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GU4YoERNTOpT"
   },
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list_gpt35, \"seed\": 42}\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"User_proxy\",\n",
    "   system_message=\"A human admin.\",\n",
    "   code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    "   human_input_mode=\"TERMINATE\"\n",
    ")\n",
    "\n",
    "chef = autogen.AssistantAgent(\n",
    "    name=\"Chef\",\n",
    "    system_message=\"\"\"Analyze the plan suggested by the Planner. Prepare the food.\n",
    "                    Provide cost estimates and feel free to suggest revisions to the plan made by the planner\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=\"\"\"Planner. Pick an Indian festival of your choice to prepare food for 300 people.\n",
    "                      Suggest a plan and prepare a menu.\n",
    "                      Revise the plan based on feedback from the Chef till a feasible plan is made.\n",
    "                      The meal must consider the food choice of everyone from all age groups.\n",
    "                      Explain the plan first. Be clear which plan was chosen finally by the Chef.\n",
    "                      Prepare a comprehensive menu and a summary of estimated expenses in INR.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, chef, planner], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTPDkO7vTOsu",
    "outputId": "3960211a-1864-46e1-b82a-05e6f518e760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_proxy (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:34:23] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 10-23 16:34:23] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner (to chat_manager):\n",
      "\n",
      "Plan:\n",
      "\n",
      "The Indian festival chosen for this task is Diwali, the Festival of Lights.\n",
      "\n",
      "The meal planning strategy is to include popular dishes from various regions of India to cater to varying tastes and age groups. Attention will be paid to ensure the availability of both vegetarian and non-vegetarian options, and a variety of sweet dishes, keeping in mind the significance of sweets during Diwali.\n",
      "\n",
      "Plan Details:\n",
      "\n",
      "1. Starters: There will be both vegetarian and non-vegetarian starters. The starters will be light and tasty to kick-off the meal.\n",
      "\n",
      "2. Main course: The main course will comprise of several dishes. There will be vegetarian and non-vegetarian options, along with rice, different types of bread, dal, and curd.\n",
      "\n",
      "3. Desserts: Diwali is incomplete without sweets. Therefore, there will be traditional Indian sweets, along with some fusion dess\n",
      "\n",
      "4. Beverages: To balance the heavy meal, light and refreshing traditional Indian beverages will be served.\n",
      "\n",
      "Menu:\n",
      "\n",
      "Starters:\n",
      "- Veg Samosa\n",
      "- Paneer Tikka\n",
      "- Chicken 65\n",
      "- Mutton Kebab\n",
      "\n",
      "Main Course:\n",
      "- Veg Biryani\n",
      "- Chicken Biryani\n",
      "- Paneer Butter Masala\n",
      "- Rogan Josh\n",
      "- Dal Makhani\n",
      "- Assorted Indian bread (Naan, Roti, Kulcha)\n",
      "- Steamed Rice\n",
      "- Curd Rice\n",
      "\n",
      "Desserts:\n",
      "- Gulab Jamun\n",
      "- Rasmalai\n",
      "- Gajar Ka Halwa\n",
      "\n",
      "Beverages:\n",
      "- Masala Chai\n",
      "- Mint Lemonade\n",
      "- Lassi\n",
      "\n",
      "Budget:\n",
      "Considering that this is a mass scale event, buying ingredients in bulk will cost about INR 400 per person. This amount will cover all the ingredients, rental of cooking and serving equipments, payment for cooks, helpers, and cleaning staff.\n",
      "\n",
      "Please let me know your suggestions or changes, Chef.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:35:00] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 10-23 16:35:01] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chef (to chat_manager):\n",
      "\n",
      "The plan seems comprehensive and well thought. However, there are a few suggestions that I would like to make:\n",
      "\n",
      "1. For Starters, I noticed you've included Paneer Tikka & Veg Samosa for the vegetarians and Chicken 65 & Mutton Kebab for non-vegetarians. While these are all good choices, in order to bring diversity and cover dietary preferences, we can introduce a vegan option as well such as a mixed vegetable Pakora plate and also some seafood like Tandoori Prawns. Adding these would increase our cost per person by approximately INR 50.\n",
      "\n",
      "2. In the Main Course, while you've covered essential dishes, adding an iconic dish for Diwali celebration such as Poori-Subzi would be appreciated by our guests. The cost increase with this addition would not be significant.\n",
      "\n",
      "3. For Desserts, along with Gulab Jamun, Rasmalai, and Gajar Ka Halwa, we could consider adding a Dry fruit-based sweet like Kaju Katli or Soan Papdi which is traditionally associated with Diwali. This may add another INR 20-25 per person.\n",
      "\n",
      "4. In terms of Beverages, the choice of Masala Chai, Mint Lemonade and Lassi is good. Often thought for big gatherings, large jars of water infused with mint and lemon can be kept for guests to help themselves, it would cost relatively less and serve many.\n",
      "\n",
      "After considering the cost of additional staff for serving and cleaning, rental costs for bigger pots and pans, utensils, fuel etc., we could be looking at an estimated cost of INR 500 - 550 per person as the updated budget. \n",
      "\n",
      "This budget allows us to keep the traditional spirit of Diwali alive, cater to various dietary preferences and ensures everyone has a good time.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:35:36] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 10-23 16:35:37] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner (to chat_manager):\n",
      "\n",
      "Thank you for your valuable suggestions, Chef. Based on your feedback, we are revising our original plan.\n",
      "\n",
      "Revised Plan:\n",
      "\n",
      "1. Starters: We will stick to the Veg Samosa and Paneer Tikka as vegetarian options, but to provide an option for our vegan guests, we will include mixed Vegetable Pakora. The non-vegetarian starters would still consist of Chicken 65 and Mutton Kebab, with the addition of Tandoori Prawns for seafood lovers.\n",
      "\n",
      "2. Main Course: Added to our preliminary selection, Poori-Subzi will also be served as a signature Diwali dish. The rest of the main course options remain the same.\n",
      "\n",
      "3. Desserts: As per your suggestion, we will include Kaju Katli in our dessert menu, along with Gulab Jamun, Rasmai and Gajar Ka Halwa.\n",
      "\n",
      "4. Beverages: In addition to Masala Chai, Mint Lemonade and Lassi, we will arrange large jars of water infused with mint and lemon as a refreshing and cost-effective option.\n",
      "\n",
      "Here's the final menu: \n",
      "\n",
      "Menu:\n",
      "\n",
      "Starters:\n",
      "- Veg Samosa\n",
      "- Paneer Tikka\n",
      "- Mixed Vegetable Pakora\n",
      "- Chicken 65\n",
      "- Mutton Kebab\n",
      "- Tandoori Prawns\n",
      "\n",
      "Main Course:\n",
      "- Veg Biryani\n",
      "- Chicken Biryani\n",
      "- Poori-Subzi\n",
      "- Paneer Butter Masala\n",
      "- Rogan Josh\n",
      "- Dal Makhani\n",
      "- Assorted Indian Bread (Naan, Roti, Kulcha)\n",
      "- Steamed Rice\n",
      "- Curd Rice\n",
      "\n",
      "Desserts:\n",
      "- Gulab Jamun\n",
      "- Rasmalai\n",
      "- Gajar Ka Halwa\n",
      "- Kaju Katli\n",
      "\n",
      "Beverages:\n",
      "- Masala Chai\n",
      "- Mint Lemonade\n",
      "- Lassi\n",
      "- Mint Infused Water\n",
      "\n",
      "The estimated expenses now increased to INR 500-550 per person. This new budget includes all additions as per your suggestions, and it covers all the ingredients, cooking and serving equipment rentals, payments for cooks, helpers, and cleaning staff. We are now equipped to deliver a complete, diverse, and satisfying meal for all of our 300 guests.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:36:23] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>> USING AUTO REPLY...\n",
      "User_proxy (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:36:24] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 10-23 16:36:24] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chef (to chat_manager):\n",
      "\n",
      "The revised plan is detailed and all-encompassing. However, since we are catering to a crowd, it is always advisable to factor in contingencies, food preferences, and subsequent repairs and maintenance of equipment. Therefore, it would be prudent to designate a contingency budget of around 10% of our planned cost. Hence, the final budget would potentially increase to around INR 600 per person.\n",
      "\n",
      "This budget would also account for potential increase in prices of certain ingredients or any last-minute addition that might be required. Now, with these few adjustments, the revised proposed budget and food plan is better aligned to potential scenarios and will ensure a smooth and successful execution.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:36:39] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 10-23 16:36:40] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner (to chat_manager):\n",
      "\n",
      "Thank you for your valuable input once again, Chef. We are aligning our revised plan with it.\n",
      "\n",
      "We now factor in a contingency plan, increase the overall budget by approximately 10% to account for any unexpected expenses, food preferences, and sudden equipment repairs and maintenances which typically can arise in such large scale operations. So, the new budget, including all these, will be around INR 600 per person.\n",
      "\n",
      "Final Budget Overview: \n",
      "\n",
      "- Budget per person: INR 600\n",
      "- Total Budget (for 300 people): INR 180,000.\n",
      "\n",
      "Final Plan & Menu:\n",
      "\n",
      "- For the Starters, we will now serve Veg Samosa, Paneer Tikka, Mixed Vegetable Pakora. For the non-vegan guests, there will be Chicken 65, Mutton Kebab, and Tandoori Prawns.\n",
      "\n",
      "- The Main Course will consist of traditional Diwali specialty Poori-Subzi, Veg Biryani, Chicken Biryani, Paneer Butter Masala, Rogan Josh, Dal Makhani, and Assorted Indian Bread, with Steamed Rice and Curd Rice.\n",
      "\n",
      "- The Dessert options will consist of traditional Diwali sweet Kaju Katli, along with other Indian desserts like Gulab Jamun, Rasmalai, and Gajar Ka Halwa.\n",
      "\n",
      "- For the Beverages, we will serve the choice of Masala Chai, Mint Lemonade, Lassi, and also arrange large jars of refreshing Mint Infused Water.\n",
      "\n",
      "This final plan and budget should make the Diwali meal a great success while meeting the taste preference of every guest.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:37:12] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>> USING AUTO REPLY...\n",
      "User_proxy (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:37:12] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 10-23 16:37:13] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chef (to chat_manager):\n",
      "\n",
      "This updated plan is detailed and robust. The changes reflect the necessary adjustments needed to encompass the diverse food preferences of the guests as well as account for unforeseen circumstances. The final budget of INR 600 per person is realistic and adequate. \n",
      "\n",
      "Good implementation of this plan would ensure a successful event where everyone can enjoy a delightful array of dishes in the spirit of Diwali. The different food choices cater to various dietary restrictions and preferences making it inclusive. \n",
      "\n",
      "The selection of desserts and beverages complements the meal well. The consideration of a traditional drink like masala chai, along with the provision of refreshing selections like mint lemonade and mint-infused water, will ensure the guests remain hydrated and refreshed.\n",
      "\n",
      "In summation, the plan is well-rounded, considers all necessary factors, and should present a successful Diwali celebration with authentic Indian cuisine that everyone can enjoy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:37:31] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>> USING AUTO REPLY...\n",
      "User_proxy (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:37:31] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 10-23 16:37:32] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner (to chat_manager):\n",
      "\n",
      "Thank you very much, Chef! Your contributions were invaluable in creating a comprehensive plan that considers every detail and hits the right notes in terms of food preferences, diversity, contingency and tradition. \n",
      "\n",
      "So, The final plan we've decided with Chef is as follows:\n",
      "\n",
      "- The event is for Diwali, and we are expecting 300 guests.\n",
      "- We have prepared a diverse menu that includes Starters, Main Course, Desserts, and Beverages with Vegetarian, Vegan, and Non-Vegetarian options.\n",
      "- We have factored in a contingency plan in the budget for any unexpected expenses or last-minute changes.\n",
      "\n",
      "The final menu:\n",
      "\n",
      "Starters:\n",
      "- Veg Samosa\n",
      "- Paneer Tikka\n",
      "- Mixed Vegetable Pakora\n",
      "- Chicken 65\n",
      "- Mutton Kebab\n",
      "- Tandoori Prawns\n",
      "\n",
      "Main Course:\n",
      "- Veg Biryani\n",
      "- Chicken Biryani\n",
      "- Poori-Subzi\n",
      "- Paneer Butter Masala\n",
      "- Rogan Josh\n",
      "- Dal Makhani\n",
      "- Assorted Indian Bread\n",
      "- Steamed Rice\n",
      "- Curd Rice\n",
      "\n",
      "Desserts:\n",
      "- Gulab Jamun\n",
      "- Rasmalai\n",
      "- Gajar Ka Halwa\n",
      "- Kaju Katli\n",
      "\n",
      "Beverages:\n",
      "- Masala Chai\n",
      "- Mint Lemonade\n",
      "- Lassi\n",
      "- Mint Infused Water.\n",
      "\n",
      "Our final budget per person after considering contingencies is INR 600, bringing the total to INR 180,000 for the complete event for 300 people.\n",
      "\n",
      "We are now ready to proceed with this plan, anticipating a successful and enjoyable Diwali celebration!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 10-23 16:38:06] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>> USING AUTO REPLY...\n",
      "User_proxy (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(manager, message=\"\")\n",
    "# type exit to terminate the chat"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
